{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CIFAR with the `policy` module\n",
    "\n",
    "Let's install the latest version of Poutyne (if it's not already) and import all the needed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "Requirement already up-to-date: poutyne in /home/fredy/.venv/base/lib/python3.8/site-packages (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /home/fredy/.venv/base/lib/python3.8/site-packages (from poutyne) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: torch in /home/fredy/.venv/base/lib/python3.8/site-packages (from poutyne) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: future in /home/fredy/.venv/base/lib/python3.8/site-packages (from torch->poutyne) (0.18.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade poutyne\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from poutyne import Model, OptimizerPolicy, one_cycle_phases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training constant\n",
    "But first, let's set the training constants, the CUDA device used for training if one is present, we set the batch size (i.e. the number of elements to see before updating the model) and the number of epochs (i.e. the number of times we see the full dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = 0\n",
    "device = torch.device(\"cuda:%d\" % cuda_device if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size = 1024\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_mean = [0.485, 0.456, 0.406]\n",
    "_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(.3, .3, .3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(_mean, _std),\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(_mean, _std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "root = \"datasets\"\n",
    "train_ds = datasets.CIFAR10(root, train=True, transform=train_transform, download=True)\n",
    "val_ds = datasets.CIFAR10(root, train=False, transform=val_transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model\n",
    "We'll train a simple `resNet-18` network.\n",
    "This takes a while without GPU but is pretty quick with GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_module():\n",
    "    model = resnet18(pretrained=False)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    model.fc = nn.Linear(512, 10)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training without the `policies` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mEpoch: \u001b[94m1/5 \u001b[93mStep: \u001b[94m49/49 \u001b[93m100.00% |\u001b[92m█████████████████████████\u001b[93m|\u001b[32m8.71s \u001b[93mloss:\u001b[96m 2.115406\u001b[93m acc:\u001b[96m 22.852000\u001b[93m val_loss:\u001b[96m 1.870449\u001b[93m val_acc:\u001b[96m 32.520000\u001b[0m\n",
      "\u001b[93mEpoch: \u001b[94m2/5 \u001b[93mStep: \u001b[94m49/49 \u001b[93m100.00% |\u001b[92m█████████████████████████\u001b[93m|\u001b[32m8.59s \u001b[93mloss:\u001b[96m 1.789251\u001b[93m acc:\u001b[96m 34.850000\u001b[93m val_loss:\u001b[96m 1.664176\u001b[93m val_acc:\u001b[96m 39.490000\u001b[0m\n",
      "\u001b[93mEpoch: \u001b[94m3/5 \u001b[93mStep: \u001b[94m49/49 \u001b[93m100.00% |\u001b[92m█████████████████████████\u001b[93m|\u001b[32m8.58s \u001b[93mloss:\u001b[96m 1.638004\u001b[93m acc:\u001b[96m 40.164000\u001b[93m val_loss:\u001b[96m 1.560369\u001b[93m val_acc:\u001b[96m 42.310000\u001b[0m\n",
      "\u001b[93mEpoch: \u001b[94m4/5 \u001b[93mStep: \u001b[94m49/49 \u001b[93m100.00% |\u001b[92m█████████████████████████\u001b[93m|\u001b[32m8.76s \u001b[93mloss:\u001b[96m 1.558112\u001b[93m acc:\u001b[96m 43.102000\u001b[93m val_loss:\u001b[96m 1.494177\u001b[93m val_acc:\u001b[96m 45.360000\u001b[0m\n",
      "\u001b[93mEpoch: \u001b[94m5/5 \u001b[93mStep: \u001b[94m49/49 \u001b[93m100.00% |\u001b[92m█████████████████████████\u001b[93m|\u001b[32m8.70s \u001b[93mloss:\u001b[96m 1.493087\u001b[93m acc:\u001b[96m 45.810000\u001b[93m val_loss:\u001b[96m 1.469608\u001b[93m val_acc:\u001b[96m 46.800000\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pytorch_network = get_module()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(pytorch_network.parameters(), lr=0.01)\n",
    "\n",
    "model = Model(\n",
    "    pytorch_network,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    batch_metrics=[\"acc\"],\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_dl,\n",
    "    val_dl,\n",
    "    epochs=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with the `policies` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = len(train_dl)\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mEpoch: \u001b[94m1/5 \u001b[93mStep: \u001b[94m49/49 \u001b[93m100.00% |\u001b[92m█████████████████████████\u001b[93m|\u001b[32m8.62s \u001b[93mloss:\u001b[96m 1.848409\u001b[93m acc:\u001b[96m 33.260000\u001b[93m val_loss:\u001b[96m 1.755679\u001b[93m val_acc:\u001b[96m 42.600000\u001b[0m\n",
      "\u001b[93mEpoch: \u001b[94m2/5 \u001b[93mStep: \u001b[94m49/49 \u001b[93m100.00% |\u001b[92m█████████████████████████\u001b[93m|\u001b[32m8.73s \u001b[93mloss:\u001b[96m 1.380307\u001b[93m acc:\u001b[96m 50.424000\u001b[93m val_loss:\u001b[96m 1.286768\u001b[93m val_acc:\u001b[96m 54.810000\u001b[0m\n",
      "\u001b[93mEpoch: \u001b[94m3/5 \u001b[93mStep: \u001b[94m49/49 \u001b[93m100.00% |\u001b[92m█████████████████████████\u001b[93m|\u001b[32m8.61s \u001b[93mloss:\u001b[96m 1.170797\u001b[93m acc:\u001b[96m 58.460000\u001b[93m val_loss:\u001b[96m 1.094710\u001b[93m val_acc:\u001b[96m 60.010000\u001b[0m\n",
      "\u001b[93mEpoch: \u001b[94m4/5 \u001b[93mStep: \u001b[94m49/49 \u001b[93m100.00% |\u001b[92m█████████████████████████\u001b[93m|\u001b[32m8.62s \u001b[93mloss:\u001b[96m 0.970011\u001b[93m acc:\u001b[96m 65.824000\u001b[93m val_loss:\u001b[96m 0.938677\u001b[93m val_acc:\u001b[96m 67.060000\u001b[0m\n",
      "\u001b[93mEpoch: \u001b[94m5/5 \u001b[93mStep: \u001b[94m49/49 \u001b[93m100.00% |\u001b[92m█████████████████████████\u001b[93m|\u001b[32m8.80s \u001b[93mloss:\u001b[96m 0.809022\u001b[93m acc:\u001b[96m 71.444000\u001b[93m val_loss:\u001b[96m 0.871968\u001b[93m val_acc:\u001b[96m 69.920000\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pytorch_network = get_module()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(pytorch_network.parameters(), lr=0.01)\n",
    "\n",
    "model = Model(\n",
    "    pytorch_network,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    batch_metrics=[\"acc\"],\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "policy = OptimizerPolicy(\n",
    "    one_cycle_phases(epochs * steps_per_epoch, lr=(0.01, 0.1, 0.008)),\n",
    ")\n",
    "history = model.fit_generator(\n",
    "    train_dl,\n",
    "    val_dl,\n",
    "    epochs=epochs,\n",
    "    callbacks=[policy],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
